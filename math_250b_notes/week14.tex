\section{Week 14}

\subsection{Bernstein-Sato Polynomial}
Recall the Gamma function $\G(s)$ is defined for $\Re(s) > 0$ by
\[
    \G(s) = \int_0^\i e^{-t}t^{s-1}dt.
\]
Via integration by parts, one can prove $\G(s) = \G(s+1)/s$. This allows one to analytically extend $\G(s)$ to the whole complex plane (possibly with poles).

It happens that this analytic continuation depends on the identity
\[
    \frac{d}{dt}t^{s+1} = (s+1)t^s.
\]
We can generalize this notion with the Bernstein-Sato polynomial. Suppose $f(x)$ is a polynomial in several variables. If we can find a differential operator $P(s)$ and monic polynomial $b(s)$ of minimal degree such that
\[
    P(s)f(x)^{s+1} = b(s)f(x)^s
\]
then $b(s)$ is the Bernstein-Sato polynomial of $f$. [Note our restrictions on $b$ make $b$ and $P$ unique.] For $f \geq 0$, the existence of the Bernstein-Sato polynomial allows us to extend
\[
    s \mapsto \int_{\bR^n}\var(x)f(x)^s dx
\]
to the complex plane (where $\var$ is some nice test function).

\subsection{Existence of Bernstein-Sato Polynomials}
It is a theorem that every nonzero polynomial has a Bernstein-Sato polynomial. To prove this, we will have to develop some machinery.

\paragraph{Bernstein's Inequality.} Define a Weyl algebra to be a noncommutative ring of the form
\[
    A = \bC\left[ x_1, \dots, x_n, \frac{\partial}{\partial x_1}, \dots, \frac{\partial}{\partial x_n}  \right].
\]
Note $A$ is almost commutative and can be made into a commutative ring $R$ in the following manner:
\begin{enumerate}
    \item We define a filtration $A_0 \subset A_1 \subset A_2 \dots$ where $A_i$ is spanned by all monomials of degree $< i$.
    \item If $p \in A_i$, $q \in A_j$, observe $pq \in A_{i + j}$ and $[p,q] \in A_{i + j -1}$. (Here, $[\cdot]$ denotes the commutator.) Thus
    \[
        R = A_0 \oplus A_1/A_0 \oplus \dots
    \]
    is a commutative graded ring.
\end{enumerate}
Now suppose $M$ is a module over $A$ generated by a f.g. $\bC$-v.s. $M_0$. Denoting $M_i = M_0A_i$, one can show
\[
    M_0 \oplus M_1/M_0 \oplus \dots
\]
is a graded module over $R$. Consequently, we can find the corresponding Hilbert polynomial and take the degree to define $\dim(M)$. It happens this is well-defined no matter the choice of $M_0$.

Bernstein's inequality states that $\dim(M) \ge n$. The proof is to show there is a natural injective map
\[
    A_i \to \Hom(M_i, M_{2i})
\]
and then compare the dimensions of $A_i$ and $\Hom(M_i, M_{2i})$. When $\dim(M) = n$, we call $M$ holonomic.

\paragraph{Holonomic Modules.} One can show that holonomic modules have finite length. The existence proof of the Bernstein-Sato polynomial then continues in the following manner:
\begin{enumerate}
    \item For polynomial $f$, we show $\bC(s)[x_1, \dots, x_n, f^{-1}]f^{-s}$ is holonomic over $A$.
    \item By the finite length condition, the chain
    \[
        Af^s \supset Af^{s+1} \supset \cdots
    \]
    eventually stabilizes, giving us $Af^{s+k} = Af^{s+k+1}$. After tweaking, this gives us the Bernstein-Sato polynomial.
\end{enumerate}

\subsection{Application}
The existence of Bernstein-Sato polynomials allows us to show that every nonzero polynomial $f(x)$ has a inverse that is a distribution. The proof is the following: 
\begin{enumerate}
    \item We reduce to the case $f \geq 0$ by writing $f = f/f^2$, and noting $f^2 \geq 0$.
    \item Using the Bernstein-Sato polynomials, we can define $f(x)^s$ as a distribution for each $s \in \bC$, barring poles. It is tempting to just set $s = -1$, but we might have a pole at $s = -1$, so instead we write $f(x)^s$ as a Laurent series (with coefficents being distributions) around $s = -1$ and take the constant term.
\end{enumerate}
This result allows us to prove the Malgrange-Ehrenpreis theorem, which states the every differential operator $D$ has a solution $f$ to the equation
\[
    Df = \d.
\]
[This is called the fundamental solution, and is used to generated other solutions.] The proof is to take Fourier transforms (so $D$ becomes a polynomial $Q$), multiply both sides by $Q^{-1}$, and then take the inverse Fourier transform. [The original proof was much harder.]

%%% Local Variables:
%%% TeX-master: "main"
%%% End: